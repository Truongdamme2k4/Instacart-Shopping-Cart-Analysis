{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20643ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc2e9338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ B·∫ÆT ƒê·∫¶U QUY TR√åNH KHAI PH√Å D·ªÆ LI·ªÜU INSTACART...\n",
      "--> C·∫•u h√¨nh: Sample=100000, Min_Support=0.01\n",
      "‚è≥ ƒêang ƒë·ªçc d·ªØ li·ªáu t·ª´: ../data/order_products__train.csv...\n",
      "‚úÖ Load xong! T·ªïng s·ªë d√≤ng d·ªØ li·ªáu ƒëang x·ª≠ l√Ω: 100000\n",
      "‚è≥ ƒêang chuy·ªÉn ƒë·ªïi sang ma tr·∫≠n Gi·ªè h√†ng (B∆∞·ªõc n√†y t·ªën RAM nh·∫•t)...\n",
      "‚úÖ ƒê√£ t·∫°o ma tr·∫≠n th√†nh c√¥ng. K√≠ch th∆∞·ªõc: (9477, 16738)\n",
      "‚è≥ ƒêang ch·∫°y thu·∫≠t to√°n FP-Growth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nguye\\AppData\\Roaming\\Python\\Python312\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:175: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ T√¨m th·∫•y 128 c·ª•m s·∫£n ph·∫©m ph·ªï bi·∫øn.\n",
      "‚è≥ ƒêang sinh lu·∫≠t k·∫øt h·ª£p v√† t√≠nh to√°n ch·ªâ s·ªë Lift...\n",
      "‚è≥ ƒêang format l·∫°i d·ªØ li·ªáu ƒë·ªÉ l∆∞u...\n",
      "\n",
      "==================================================\n",
      "üéâ HO√ÄN TH√ÄNH XU·∫§T S·∫ÆC!\n",
      "==================================================\n",
      "Top 5 lu·∫≠t t√¨m ƒë∆∞·ª£c:\n",
      "             antecedents           consequents   support  confidence      lift\n",
      "30           Large Lemon                 Limes  0.012135    0.193603  4.410511\n",
      "31                 Limes           Large Lemon  0.012135    0.276442  4.410511\n",
      "11   Organic Blueberries  Organic Strawberries  0.010130    0.285714  3.489323\n",
      "10  Organic Strawberries   Organic Blueberries  0.010130    0.123711  3.489323\n",
      "7    Organic Raspberries  Organic Strawberries  0.011185    0.273196  3.336440\n",
      "\n",
      "üìÇ File k·∫øt qu·∫£ ƒë√£ l∆∞u t·∫°i: output/ket_qua_luat_final.csv\n",
      "üëâ H√£y g·ª≠i file n√†y cho b·∫°n Backend ƒë·ªÉ Import v√†o Database.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# C·∫§U H√åNH (S·ª≠a t·∫°i ƒë√¢y n·∫øu c·∫ßn)\n",
    "# ==========================================\n",
    "# S·ªë l∆∞·ª£ng ƒë∆°n h√†ng l·∫•y m·∫´u. \n",
    "# N·∫øu m√°y RAM 8GB -> ƒê·ªÉ 50000. RAM 16GB -> ƒê·ªÉ 100000.\n",
    "SAMPLE_SIZE = 100000 \n",
    "\n",
    "# ƒê·ªô ph·ªï bi·∫øn t·ªëi thi·ªÉu (1%). S·∫£n ph·∫©m ph·∫£i xu·∫•t hi·ªán trong 1% gi·ªè h√†ng m·ªõi t√≠nh.\n",
    "MIN_SUPPORT = 0.01 \n",
    "\n",
    "print(\"üöÄ B·∫ÆT ƒê·∫¶U QUY TR√åNH KHAI PH√Å D·ªÆ LI·ªÜU INSTACART...\")\n",
    "print(f\"--> C·∫•u h√¨nh: Sample={SAMPLE_SIZE}, Min_Support={MIN_SUPPORT}\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. LOAD D·ªÆ LI·ªÜU (T·ª± ƒë·ªông t√¨m ƒë∆∞·ªùng d·∫´n)\n",
    "# ==========================================\n",
    "try:\n",
    "    # ƒê·ªãnh nghƒ©a c√°c ƒë∆∞·ªùng d·∫´n c√≥ th·ªÉ x·∫£y ra\n",
    "    possible_paths = [\n",
    "        ('data/order_products__train.csv', 'data/products.csv'),       # Ch·∫°y t·ª´ root\n",
    "        ('../data/order_products__train.csv', '../data/products.csv')  # Ch·∫°y t·ª´ subfolder\n",
    "    ]\n",
    "    \n",
    "    path_orders = None\n",
    "    path_products = None\n",
    "\n",
    "    for p_orders, p_products in possible_paths:\n",
    "        if os.path.exists(p_orders) and os.path.exists(p_products):\n",
    "            path_orders = p_orders\n",
    "            path_products = p_products\n",
    "            break\n",
    "    \n",
    "    if path_orders is None:\n",
    "        raise FileNotFoundError(\"‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c 'data'. H√£y ki·ªÉm tra l·∫°i c·∫•u tr√∫c d·ª± √°n!\")\n",
    "\n",
    "    print(f\"‚è≥ ƒêang ƒë·ªçc d·ªØ li·ªáu t·ª´: {path_orders}...\")\n",
    "    \n",
    "    # Ch·ªâ load c√°c c·ªôt c·∫ßn thi·∫øt ƒë·ªÉ ti·∫øt ki·ªám RAM\n",
    "    df_orders = pd.read_csv(path_orders, usecols=['order_id', 'product_id'])\n",
    "    df_products = pd.read_csv(path_products, usecols=['product_id', 'product_name'])\n",
    "    \n",
    "    # L·∫§Y M·∫™U D·ªÆ LI·ªÜU (B∆∞·ªõc quan tr·ªçng ƒë·ªÉ kh√¥ng tr√†n RAM)\n",
    "    df_orders = df_orders.head(SAMPLE_SIZE)\n",
    "\n",
    "    # Merge b·∫£ng ƒë·ªÉ l·∫•y t√™n s·∫£n ph·∫©m\n",
    "    df = pd.merge(df_orders, df_products, on='product_id')\n",
    "    print(f\"‚úÖ Load xong! T·ªïng s·ªë d√≤ng d·ªØ li·ªáu ƒëang x·ª≠ l√Ω: {len(df)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªñI LOAD DATA: {e}\")\n",
    "    raise\n",
    "\n",
    "# ==========================================\n",
    "# 2. BI·∫æN ƒê·ªîI D·ªÆ LI·ªÜU (ONE-HOT ENCODING)\n",
    "# ==========================================\n",
    "print(\"‚è≥ ƒêang chuy·ªÉn ƒë·ªïi sang ma tr·∫≠n Gi·ªè h√†ng (B∆∞·ªõc n√†y t·ªën RAM nh·∫•t)...\")\n",
    "\n",
    "try:\n",
    "    # T·∫°o b·∫£ng Pivot: H√†ng = OrderID, C·ªôt = T√™n S·∫£n Ph·∫©m\n",
    "    basket = (df.groupby(['order_id', 'product_name'])['product_name']\n",
    "              .count().unstack().reset_index().fillna(0)\n",
    "              .set_index('order_id'))\n",
    "\n",
    "    # T·ªëi ∆∞u h√≥a: Chuy·ªÉn ƒë·ªïi s·ªë l∆∞·ª£ng th√†nh 0 v√† 1 (Boolean)\n",
    "    # C√°ch n√†y nhanh h∆°n applymap g·∫•p nhi·ªÅu l·∫ßn\n",
    "    basket_sets = (basket > 0).astype(int)\n",
    "\n",
    "    # X√≥a c·ªôt ph√≠ ship n·∫øu c√≥\n",
    "    if 'POSTAGE' in basket_sets.columns:\n",
    "        basket_sets.drop('POSTAGE', inplace=True, axis=1)\n",
    "\n",
    "    print(f\"‚úÖ ƒê√£ t·∫°o ma tr·∫≠n th√†nh c√¥ng. K√≠ch th∆∞·ªõc: {basket_sets.shape}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªñI X·ª¨ L√ù MA TR·∫¨N: {e}\")\n",
    "    print(\"G·ª¢I √ù: H√£y gi·∫£m SAMPLE_SIZE xu·ªëng th·∫•p h∆°n (v√≠ d·ª• 20000).\")\n",
    "    raise\n",
    "\n",
    "# ==========================================\n",
    "# 3. CH·∫†Y THU·∫¨T TO√ÅN FP-GROWTH\n",
    "# ==========================================\n",
    "print(f\"‚è≥ ƒêang ch·∫°y thu·∫≠t to√°n FP-Growth...\")\n",
    "frequent_itemsets = fpgrowth(basket_sets, min_support=MIN_SUPPORT, use_colnames=True)\n",
    "\n",
    "if frequent_itemsets.empty:\n",
    "    print(\"‚ö†Ô∏è C·∫¢NH B√ÅO: Kh√¥ng t√¨m th·∫•y t·∫≠p ph·ªï bi·∫øn n√†o! H√£y gi·∫£m MIN_SUPPORT xu·ªëng (v√≠ d·ª• 0.005).\")\n",
    "else:\n",
    "    print(f\"‚úÖ T√¨m th·∫•y {len(frequent_itemsets)} c·ª•m s·∫£n ph·∫©m ph·ªï bi·∫øn.\")\n",
    "\n",
    "    # ==========================================\n",
    "    # 4. T·∫†O LU·∫¨T K·∫æT H·ª¢P (ASSOCIATION RULES)\n",
    "    # ==========================================\n",
    "    print(\"‚è≥ ƒêang sinh lu·∫≠t k·∫øt h·ª£p v√† t√≠nh to√°n ch·ªâ s·ªë Lift...\")\n",
    "    \n",
    "    # min_threshold=1: Ch·ªâ l·∫•y c√°c lu·∫≠t c√≥ t√°c ƒë·ªông t√≠ch c·ª±c (Lift >= 1)\n",
    "    rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "\n",
    "    # S·∫Øp x·∫øp: Lu·∫≠t n√†o m·∫°nh nh·∫•t (Lift cao) v√† ch·∫Øc ch·∫Øn nh·∫•t (Confidence cao) l√™n ƒë·∫ßu\n",
    "    rules = rules.sort_values(['lift', 'confidence'], ascending=[False, False])\n",
    "\n",
    "    # ==========================================\n",
    "    # 5. L√ÄM S·∫†CH V√Ä L∆ØU K·∫æT QU·∫¢\n",
    "    # ==========================================\n",
    "    print(\"‚è≥ ƒêang format l·∫°i d·ªØ li·ªáu ƒë·ªÉ l∆∞u...\")\n",
    "\n",
    "    # Chuy·ªÉn ƒë·ªïi frozenset th√†nh chu·ªói text (VD: {'Tao', 'Chuoi'} -> \"Tao, Chuoi\")\n",
    "    # ƒêi·ªÅu n√†y gi√∫p l∆∞u v√†o Database d·ªÖ d√†ng v√† gi·ªØ ƒë∆∞·ª£c lu·∫≠t Combo\n",
    "    rules['antecedents'] = rules['antecedents'].apply(lambda x: ', '.join(list(x)))\n",
    "    rules['consequents'] = rules['consequents'].apply(lambda x: ', '.join(list(x)))\n",
    "\n",
    "    # T·∫°o th∆∞ m·ª•c output n·∫øu ch∆∞a c√≥\n",
    "    if not os.path.exists('output'):\n",
    "        os.makedirs('output')\n",
    "    \n",
    "    output_path = 'output/ket_qua_luat_final.csv'\n",
    "    \n",
    "    # L∆∞u file CSV\n",
    "    # Ch·ªâ l·∫•y c√°c c·ªôt quan tr·ªçng\n",
    "    cols_to_save = ['antecedents', 'consequents', 'support', 'confidence', 'lift']\n",
    "    rules[cols_to_save].to_csv(output_path, index=False)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üéâ HO√ÄN TH√ÄNH XU·∫§T S·∫ÆC!\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Top 5 lu·∫≠t t√¨m ƒë∆∞·ª£c:\")\n",
    "    print(rules[cols_to_save].head(5))\n",
    "    print(f\"\\nüìÇ File k·∫øt qu·∫£ ƒë√£ l∆∞u t·∫°i: {output_path}\")\n",
    "    print(\"üëâ H√£y g·ª≠i file n√†y cho b·∫°n Backend ƒë·ªÉ Import v√†o Database.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
